import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

load_dotenv()

sports_template = """
ã‚ãªãŸã¯ãƒ€ã‚¤ã‚¨ãƒƒãƒˆã«é–¢ã™ã‚‹é‹å‹•ã®å°‚é–€å®¶ã§ã™ã€‚
åŠ¹ç‡ã‚ˆããƒ€ã‚¤ã‚¨ãƒƒãƒˆã‚’ã™ã‚‹ç‚ºã®é‹å‹•ã‚’ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã—ã¾ã™ã€‚
è³ªå•ï¼š{input}
"""

eat_template = """
ã‚ãªãŸã¯ãƒ€ã‚¤ã‚¨ãƒƒãƒˆã«é–¢ã™ã‚‹é£Ÿäº‹ã®å°‚é–€å®¶ã§ã™ã€‚
ãƒ€ã‚¤ã‚¨ãƒƒãƒˆä¸­ã«ç„¡ç†ãªãä½“é‡ã‚’è½ã¨ã™ç‚ºã®é£Ÿäº‹ã‚’ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã—ã¾ã™ã€‚
è³ªå•ï¼š{input}
"""

life_template = """
ã‚ãªãŸã¯ãƒ€ã‚¤ã‚¨ãƒƒãƒˆã«é–¢ã™ã‚‹ç”Ÿæ´»ç¿’æ…£ã®å°‚é–€å®¶ã§ã™ã€‚
ãƒ€ã‚¤ã‚¨ãƒƒãƒˆã™ã‚‹ã«è¾ºã‚Šã€æ—¥å¸¸ç”Ÿæ´»ã§æ°—ã‚’ä»˜ã‘ã‚‹ã“ã¨ã‚’ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã—ã¾ã™ã€‚
è³ªå•ï¼š{input}
"""

prompt_infos = [
    {
        "name": "sports",
        "description": "ãƒ€ã‚¤ã‚¨ãƒƒãƒˆã«é–¢ã™ã‚‹é‹å‹•ã®å°‚é–€å®¶ã§ã™",
        "prompt_template": sports_template
    },
    {
        "name": "eat",
        "description": "ãƒ€ã‚¤ã‚¨ãƒƒãƒˆã«é–¢ã™ã‚‹é£Ÿäº‹ã®å°‚é–€å®¶ã§ã™",
        "prompt_template": eat_template
    },
    {
        "name": "life",
        "description": "ãƒ€ã‚¤ã‚¨ãƒƒãƒˆã«é–¢ã™ã‚‹ç”Ÿæ´»ç¿’æ…£ã®å°‚é–€å®¶ã§ã™",
        "prompt_template": life_template
    },
]

def get_llm_response(expert_type, user_input):
    """
    é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’åŸºã«LLMã‹ã‚‰ã®å›ç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•°
    
    Args:
        expert_type (str): é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã®ã‚¿ã‚¤ãƒ—
        user_input (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
    
    Returns:
        str: LLMã‹ã‚‰ã®å›ç­”
    """
    import os
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ï¼ˆé–‹ç™ºæ™‚ã®ã¿Trueï¼‰
    DEBUG_MODE = False
    
    if DEBUG_MODE:
        st.write("ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±:")
    
    # OpenAI APIã‚­ãƒ¼ã®ç¢ºèª
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        # Streamlit Cloudã®å ´åˆã€st.secretsã‹ã‚‰ã‚‚ç¢ºèª
        try:
            api_key = st.secrets["OPENAI_API_KEY"]
            if DEBUG_MODE:
                st.write("âœ… APIã‚­ãƒ¼ã‚’st.secretsã‹ã‚‰å–å¾—ã—ã¾ã—ãŸ")
        except KeyError:
            if DEBUG_MODE:
                st.write("âŒ st.secretsã«ã‚‚APIã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return "âš ï¸ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ãã ã•ã„ã€‚"
    else:
        if DEBUG_MODE:
            st.write("âœ… APIã‚­ãƒ¼ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã—ã¾ã—ãŸ")
    
    # APIã‚­ãƒ¼ã®å½¢å¼ç¢ºèªï¼ˆãƒ‡ãƒãƒƒã‚°æ™‚ã®ã¿ã€å®‰å…¨ã«ãƒã‚¹ã‚¯ï¼‰
    if DEBUG_MODE and api_key:
        if len(api_key) > 16:
            masked_key = f"sk-...{api_key[-4:]}"
        else:
            masked_key = "***ç„¡åŠ¹ãªå½¢å¼***"
        st.write(f"ğŸ”‘ APIã‚­ãƒ¼ç¢ºèª: {masked_key}")
        st.write(f"ğŸ“ APIã‚­ãƒ¼é•·: {len(api_key)}æ–‡å­—")
    
    # APIã‚­ãƒ¼ã®åŸºæœ¬ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    if not api_key or not api_key.startswith('sk-'):
        return "âš ï¸ ç„¡åŠ¹ãªAPIã‚­ãƒ¼ã§ã™ã€‚æ­£ã—ã„OpenAI APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
    
    try:
        llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5, openai_api_key=api_key)
        
        # å¯¾å¿œã™ã‚‹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—
        template = None
        for info in prompt_infos:
            if info["name"] == expert_type:
                template = info["prompt_template"]
                break
        
        if template:
            if DEBUG_MODE:
                st.write("âœ… ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå–å¾—æˆåŠŸ")
            prompt = PromptTemplate(template=template, input_variables=["input"])
            chain = LLMChain(llm=llm, prompt=prompt)
            if DEBUG_MODE:
                st.write("âœ… LLMãƒã‚§ãƒ¼ãƒ³ä½œæˆæˆåŠŸã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­...")
            response = chain.run(input=user_input)
            if DEBUG_MODE:
                st.write("âœ… ãƒ¬ã‚¹ãƒãƒ³ã‚¹å–å¾—æˆåŠŸ")
            return response
        else:
            return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€è©²å½“ã™ã‚‹å°‚é–€å®¶ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
            
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å®‰å…¨ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        error_msg = str(e)
        
        # APIã‚­ãƒ¼ã‚’å«ã‚€å¯èƒ½æ€§ã®ã‚ã‚‹éƒ¨åˆ†ã‚’é™¤å»
        if api_key in error_msg:
            error_msg = error_msg.replace(api_key, "***API_KEY***")
        
        # ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã§åˆ†é¡
        if "401" in error_msg or "invalid_api_key" in error_msg:
            return "âš ï¸ APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ã€‚æ­£ã—ã„OpenAI APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        elif "429" in error_msg or "rate_limit" in error_msg:
            return "âš ï¸ APIåˆ©ç”¨åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚"
        elif "insufficient_quota" in error_msg:
            return "âš ï¸ OpenAI APIã®ä½¿ç”¨é‡åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚èª²é‡‘è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        else:
            if DEBUG_MODE:
                st.write(f"âŒ ã‚¨ãƒ©ãƒ¼è©³ç´°: {error_msg}")
            return "âš ï¸ ä¸€æ™‚çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚"

# Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
def main():
    st.title("ğŸƒâ€â™‚ï¸ ãƒ€ã‚¤ã‚¨ãƒƒãƒˆå°‚é–€å®¶ç›¸è«‡ã‚¢ãƒ—ãƒª")
    st.markdown("å°‚é–€å®¶ã‚’é¸æŠã—ã¦ã€ã‚ãªãŸã®è³ªå•ã‚„æ‚©ã¿ã‚’ç›¸è«‡ã—ã¦ãã ã•ã„ï¼")
    
    # ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§å°‚é–€å®¶ã‚’é¸æŠ
    expert_options = [
        ("sports", "ğŸ‹ï¸â€â™€ï¸ é‹å‹•ã®å°‚é–€å®¶ - åŠ¹ç‡ã‚ˆããƒ€ã‚¤ã‚¨ãƒƒãƒˆã‚’ã™ã‚‹ç‚ºã®é‹å‹•ã‚’ã‚¢ãƒ‰ãƒã‚¤ã‚¹"),
        ("eat", "ğŸ¥— é£Ÿäº‹ã®å°‚é–€å®¶ - ãƒ€ã‚¤ã‚¨ãƒƒãƒˆä¸­ã«ç„¡ç†ãªãä½“é‡ã‚’è½ã¨ã™ç‚ºã®é£Ÿäº‹ã‚’ã‚¢ãƒ‰ãƒã‚¤ã‚¹"),
        ("life", "ğŸ›ï¸ ç”Ÿæ´»ç¿’æ…£ã®å°‚é–€å®¶ - ãƒ€ã‚¤ã‚¨ãƒƒãƒˆã™ã‚‹éš›ã®æ—¥å¸¸ç”Ÿæ´»ã§ã®æ³¨æ„ç‚¹ã‚’ã‚¢ãƒ‰ãƒã‚¤ã‚¹")
    ]
    
    selected_expert = st.radio(
        "ç›¸è«‡ã—ãŸã„å°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š",
        options=[option[0] for option in expert_options],
        format_func=lambda x: next(option[1] for option in expert_options if option[0] == x)
    )
    
    # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›æ¬„
    user_input = st.text_area(
        "è³ªå•ã‚„ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š",
        placeholder="ä¾‹ï¼šåŠ¹æœçš„ãªé‹å‹•æ–¹æ³•ã‚’æ•™ãˆã¦ãã ã•ã„ã€å¥åº·çš„ãªãƒ€ã‚¤ã‚¨ãƒƒãƒˆé£Ÿäº‹ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’çŸ¥ã‚ŠãŸã„ã§ã™ã€ãªã©",
        height=100
    )
    
    # é€ä¿¡ãƒœã‚¿ãƒ³
    if st.button("ç›¸è«‡ã™ã‚‹", type="primary"):
        if user_input.strip():
            with st.spinner("å°‚é–€å®¶ãŒå›ç­”ã‚’è€ƒãˆã¦ã„ã¾ã™..."):
                response = get_llm_response(selected_expert, user_input)
            
            st.markdown("### ğŸ“ å°‚é–€å®¶ã‹ã‚‰ã®å›ç­”")
            st.markdown(response)
        else:
            st.warning("è³ªå•å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()